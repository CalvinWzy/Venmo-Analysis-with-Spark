{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import expr\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import concat\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a file path for Java Home\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-------+-------+----------------+-------------------+------------+-----------+--------------------+\n|  user1|  user2|transaction_type|           datetime| description|is_business|            story_id|\n+-------+-------+----------------+-------------------+------------+-----------+--------------------+\n|1218774|1528945|         payment|2015-11-27 02:48:19|        Uber|      false|5657c473cd03c9af2...|\n|5109483|4782303|         payment|2015-06-17 04:37:04|      Costco|      false|5580f9702b64f70ab...|\n|4322148|3392963|         payment|2015-06-19 00:05:31|Sweaty balls|      false|55835ccb1a624b14a...|\n| 469894|1333620|          charge|2016-06-03 16:34:13|          🎥|      false|5751b185cd03c9af2...|\n|2960727|3442373|         payment|2016-05-29 16:23:42|           ⚡|      false|574b178ecd03c9af2...|\n+-------+-------+----------------+-------------------+------------+-----------+--------------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "# Import Venmo data\n",
    "MAX_MEMORY = '12g'\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName('venmo')\\\n",
    "        .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "        .getOrCreate()\n",
    "venmo=spark.read.parquet('VenmoSample.snappy.parquet')\n",
    "venmo.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Analytics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1: Use the text dictionary and the emoji dictionary to classify Venmo’s transactions in sample dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+---------+---------+--------+-------+---------------+-----------+-----+----------------+\n|   People |    Food |   Event |Activity|Travel |Transportation |   Utility | Cash|Illegal/Sarcasm |\n+----------+---------+---------+--------+-------+---------------+-----------+-----+----------------+\n|    friend|     food| birthday|    ball|  beach|           lyft|       bill| atm |       addiction|\n|friendship|      bbq|christmas|    boat|  place|           uber|      cable|bank |            drug|\n|      baby|     bean|    happy|     bar|     la|            cab|        fee|cash |           wangs|\n|       boy|    latte|     bday|    book|  world|            bus|   electric|money|            weed|\n|      girl|breakfast|  wedding|    club|  hotel|            car|electricity| buck|            anal|\n+----------+---------+---------+--------+-------+---------------+-----------+-----+----------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "# Import the stacked dictionary contained all the text and emojis\n",
    "dictionary=spark.read.csv('text_all.csv',header=True)\n",
    "dictionary.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for dictionary\n",
    "People=[row[0] for row in dictionary.select(dictionary.columns[0]).collect()]\n",
    "Food=[row[0] for row in dictionary.select(dictionary.columns[1]).collect()]\n",
    "Event=[row[0] for row in dictionary.select(dictionary.columns[2]).collect()]\n",
    "Activity=[row[0] for row in dictionary.select(dictionary.columns[3]).collect()]\n",
    "Travel=[row[0] for row in dictionary.select(dictionary.columns[4]).collect()]\n",
    "Trans=[row[0] for row in dictionary.select(dictionary.columns[5]).collect()]\n",
    "Utility=[row[0] for row in dictionary.select(dictionary.columns[6]).collect()]\n",
    "Cash=[row[0] for row in dictionary.select(dictionary.columns[7]).collect()]\n",
    "Illegal=[row[0] for row in dictionary.select(dictionary.columns[8]).collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to classify the words\n",
    "def word_type(x):\n",
    "    categories=[]\n",
    "    for var in x:\n",
    "        if var in People:\n",
    "            categories.append('People')\n",
    "        if var in Food:\n",
    "            categories.append('Food')\n",
    "        if var in Event:\n",
    "            categories.append('Event')\n",
    "        if var in Activity:\n",
    "            categories.append('Activity')\n",
    "        if var in Travel:\n",
    "            categories.append('Travel')\n",
    "        if var in Trans:\n",
    "            categories.append('Trans')\n",
    "        if var in Utility:\n",
    "            categories.append('Utility')\n",
    "        if var in Cash:\n",
    "            categories.append('Cash')\n",
    "        if var in Illegal:\n",
    "            categories.append('Illegal')\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+\n|  user1|  user2|transaction_type|           datetime| description|is_business|            story_id|          words|\n+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+\n|1218774|1528945|         payment|2015-11-27 02:48:19|        Uber|      false|5657c473cd03c9af2...|         [uber]|\n|5109483|4782303|         payment|2015-06-17 04:37:04|      Costco|      false|5580f9702b64f70ab...|       [costco]|\n|4322148|3392963|         payment|2015-06-19 00:05:31|Sweaty balls|      false|55835ccb1a624b14a...|[sweaty, balls]|\n| 469894|1333620|          charge|2016-06-03 16:34:13|          🎥|      false|5751b185cd03c9af2...|           [🎥]|\n|2960727|3442373|         payment|2016-05-29 16:23:42|           ⚡|      false|574b178ecd03c9af2...|            [⚡]|\n+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "# Tokenized the description of Venmo data\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"description\", outputCol=\"words\") \n",
    "tokenized = tokenizer.transform(venmo)\n",
    "tokenized.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use withColumn to add category\n",
    "word_type_udf=F.udf(lambda y: word_type(y), ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+---------+\n|  user1|  user2|transaction_type|           datetime| description|is_business|            story_id|          words| category|\n+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+---------+\n|1218774|1528945|         payment|2015-11-27 02:48:19|        Uber|      false|5657c473cd03c9af2...|         [uber]|  [Trans]|\n|5109483|4782303|         payment|2015-06-17 04:37:04|      Costco|      false|5580f9702b64f70ab...|       [costco]|   [Food]|\n|4322148|3392963|         payment|2015-06-19 00:05:31|Sweaty balls|      false|55835ccb1a624b14a...|[sweaty, balls]|       []|\n| 469894|1333620|          charge|2016-06-03 16:34:13|          🎥|      false|5751b185cd03c9af2...|           [🎥]|  [Event]|\n|2960727|3442373|         payment|2016-05-29 16:23:42|           ⚡|      false|574b178ecd03c9af2...|            [⚡]|[Utility]|\n+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+---------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "tokenized=tokenized.withColumn('category',word_type_udf(F.col('words')))\n",
    "tokenized.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2: What is the percent of emoji only transactions? 14.4%**\n",
    "\n",
    "**Which are the top 5 most popular emoji? 🍕🍻🍴🍺⛽**\n",
    "\n",
    "**Which are the top three most popular emoji categories? Food, People, Activity**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two columns save the emojis and words seperately\n",
    "import emoji\n",
    "is_emoji = lambda x: [val for val in x if val in emoji.UNICODE_EMOJI ]\n",
    "is_not_emoji = lambda x: [val for val in x if val not in emoji.UNICODE_EMOJI ]\n",
    "is_emoji_udf = udf(lambda z: is_emoji(z), ArrayType(StringType()))\n",
    "is_not_emoji_udf = udf(lambda z: is_not_emoji(z), ArrayType(StringType()))\n",
    "description_list=tokenized.select('user1','user2','datetime', is_emoji_udf('words').alias('emojis'),is_not_emoji_udf('words').alias('words'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-------+-------+-------------------+------+---------------+\n|  user1|  user2|           datetime|emojis|          words|\n+-------+-------+-------------------+------+---------------+\n|1218774|1528945|2015-11-27 02:48:19|    []|         [uber]|\n|5109483|4782303|2015-06-17 04:37:04|    []|       [costco]|\n|4322148|3392963|2015-06-19 00:05:31|    []|[sweaty, balls]|\n| 469894|1333620|2016-06-03 16:34:13|  [🎥]|             []|\n|2960727|3442373|2016-05-29 16:23:42|   [⚡]|             []|\n+-------+-------+-------------------+------+---------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "description_list.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to see whether the words is a empty list, if yes, then it means this description only contains emoji\n",
    "def emoji_only(x):\n",
    "    list_length=len(x)\n",
    "    if list_length:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------+-------+-------------------+------+--------------------+----------+\n|   user1|  user2|           datetime|emojis|               words|emoji_only|\n+--------+-------+-------------------+------+--------------------+----------+\n| 1218774|1528945|2015-11-27 02:48:19|    []|              [uber]|         0|\n| 5109483|4782303|2015-06-17 04:37:04|    []|            [costco]|         0|\n| 4322148|3392963|2015-06-19 00:05:31|    []|     [sweaty, balls]|         0|\n|  469894|1333620|2016-06-03 16:34:13|  [🎥]|                  []|         1|\n| 2960727|3442373|2016-05-29 16:23:42|   [⚡]|                  []|         1|\n| 3977544|2709470|2016-09-29 15:12:07|    []|        [chipotlaid]|         0|\n| 3766386|4209061|2016-05-20 03:31:15|    []|  [kitchen, counter]|         0|\n|  730075| 804466|2016-05-25 21:46:45|    []|              [food]|         0|\n| 5221751|4993533|2016-07-14 15:53:49|    []|             [zaxby]|         0|\n| 6843582|7308338|2016-08-31 03:32:46|    []|        [fan, sucks]|         0|\n| 5317324|3942984|2016-01-04 01:11:25|  [👠]|                  []|         1|\n| 1134661|1556430|2015-10-08 18:53:52|    []|      [thanks, babe]|         0|\n| 4238868|4879587|2015-10-04 01:28:01|  [🍺]|                  []|         1|\n|11719500|8702716|2016-07-07 14:40:39|   [⛽]|                  []|         1|\n| 3625798|5692302|2016-10-16 07:43:41|    []|[hey, man, , it's...|         0|\n|  613908|3045405|2016-05-06 23:42:17|    []|      [getaway, car]|         0|\n| 4682257|1870271|2016-02-24 01:14:12|  [🔮]|     [gypsy, things]|         0|\n| 9414481|2869012|2016-04-09 02:19:46|  [🔴]|                  []|         1|\n|  241386|2580543|2015-05-16 23:00:19|    []|         [furniture]|         0|\n|  656477| 656214|2013-12-14 14:43:27|    []|[bed, bath, mostl...|         0|\n+--------+-------+-------------------+------+--------------------+----------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "emoji_only_udf=udf(lambda z:emoji_only(z),IntegerType())\n",
    "description_list.select('user1','user2','datetime','emojis','words',emoji_only_udf('words').alias('emoji_only')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_only_table=description_list.select('user1','user2','datetime','emojis','words',emoji_only_udf('words').alias('emoji_only'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1027597"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "emoji_only_table.where('emoji_only=1').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.14446467149444753"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# The percentage of emoji only transaction\n",
    "1027597/description_list.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_emoji = lambda x: [val for val in x if val in emoji.UNICODE_EMOJI ]\n",
    "is_emoji_udf = udf(lambda z: is_emoji(z), StringType())\n",
    "emoji_string=tokenized.select('user1','user2','datetime', is_emoji_udf('words').alias('emojis'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-------+-------+-------------------+------+\n|  user1|  user2|           datetime|emojis|\n+-------+-------+-------------------+------+\n|1218774|1528945|2015-11-27 02:48:19|    []|\n|5109483|4782303|2015-06-17 04:37:04|    []|\n|4322148|3392963|2015-06-19 00:05:31|    []|\n| 469894|1333620|2016-06-03 16:34:13|  [🎥]|\n|2960727|3442373|2016-05-29 16:23:42|   [⚡]|\n+-------+-------+-------------------+------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "emoji_string.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_string.createOrReplaceTempView('emoji_string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+------+-------------+\n|emojis|count(emojis)|\n+------+-------------+\n|    []|      5677672|\n|  [🍕]|        55226|\n|  [🍻]|        43113|\n|  [🍴]|        34172|\n|  [🍺]|        28163|\n|   [⛽]|        23596|\n+------+-------------+\nonly showing top 6 rows\n\n"
    }
   ],
   "source": [
    "# Find the top 5 popolar emojis\n",
    "spark.sql('''select emojis, count(emojis) from emoji_string where emojis is not null group by emojis order by count(emojis) desc''').show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 3 category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------+-------+-------------------+------+---------+\n|   user1|  user2|           datetime|emojis| category|\n+--------+-------+-------------------+------+---------+\n| 1218774|1528945|2015-11-27 02:48:19|    []|       []|\n| 5109483|4782303|2015-06-17 04:37:04|    []|       []|\n| 4322148|3392963|2015-06-19 00:05:31|    []|       []|\n|  469894|1333620|2016-06-03 16:34:13|  [🎥]|  [Event]|\n| 2960727|3442373|2016-05-29 16:23:42|   [⚡]|[Utility]|\n| 3977544|2709470|2016-09-29 15:12:07|    []|       []|\n| 3766386|4209061|2016-05-20 03:31:15|    []|       []|\n|  730075| 804466|2016-05-25 21:46:45|    []|       []|\n| 5221751|4993533|2016-07-14 15:53:49|    []|       []|\n| 6843582|7308338|2016-08-31 03:32:46|    []|       []|\n| 5317324|3942984|2016-01-04 01:11:25|  [👠]| [People]|\n| 1134661|1556430|2015-10-08 18:53:52|    []|       []|\n| 4238868|4879587|2015-10-04 01:28:01|  [🍺]|   [Food]|\n|11719500|8702716|2016-07-07 14:40:39|   [⛽]|  [Trans]|\n| 3625798|5692302|2016-10-16 07:43:41|    []|       []|\n|  613908|3045405|2016-05-06 23:42:17|    []|       []|\n| 4682257|1870271|2016-02-24 01:14:12|  [🔮]|       []|\n| 9414481|2869012|2016-04-09 02:19:46|  [🔴]|       []|\n|  241386|2580543|2015-05-16 23:00:19|    []|       []|\n|  656477| 656214|2013-12-14 14:43:27|    []|       []|\n+--------+-------+-------------------+------+---------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "# Use the categorize function again to find the category for emojis\n",
    "emoji_string_category=emoji_string.withColumn('category',word_type_udf(F.col('emojis')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------+-------+-------------------+------+----------+\n|   user1|  user2|           datetime|emojis|  category|\n+--------+-------+-------------------+------+----------+\n|  469894|1333620|2016-06-03 16:34:13|  [🎥]|   [Event]|\n| 2960727|3442373|2016-05-29 16:23:42|   [⚡]| [Utility]|\n| 5317324|3942984|2016-01-04 01:11:25|  [👠]|  [People]|\n| 4238868|4879587|2015-10-04 01:28:01|  [🍺]|    [Food]|\n|11719500|8702716|2016-07-07 14:40:39|   [⛽]|   [Trans]|\n| 5696834|1623756|2016-05-05 19:19:29|  [🎫]|[Activity]|\n| 2743865|2896157|2015-06-10 02:30:11|  [🍕]|    [Food]|\n| 4771561|1597177|2015-11-08 05:15:22|  [🎉]|[Activity]|\n| 1217777|1080491|2015-10-24 23:52:34|  [🌮]|    [Food]|\n|  349302|2592800|2016-08-07 23:46:16|  [🍵]|    [Food]|\n| 2271571| 161995|2016-07-08 19:29:28|  [🎉]|[Activity]|\n| 2725725|4754438|2016-10-10 22:53:07|   [☕]|    [Food]|\n| 6324245| 681532|2016-05-19 03:19:46|  [🍼]|    [Food]|\n| 4897128|3575816|2015-12-16 18:47:53|  [🎁]|[Activity]|\n| 6245009|1383925|2016-06-03 00:46:07|  [🤓]|  [People]|\n| 2249219|9465615|2016-07-05 18:38:54|[🇺🇸]|   [Event]|\n| 1315586|1310673|2015-07-30 20:16:20|  [🍺]|    [Food]|\n| 9187075|8453570|2016-03-26 22:24:25|  [🍴]|    [Food]|\n| 4226498|4708480|2016-04-17 18:21:10|  [🍺]|    [Food]|\n| 2599757| 508034|2016-04-04 20:18:06|  [🍴]|    [Food]|\n+--------+-------+-------------------+------+----------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "# Remove the rows with empty category\n",
    "emoji_string_category=emoji_string_category.filter(F.size('category') > 0) # F.size can be used to see the length of column\n",
    "emoji_string_category.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+---------------+\n|  category|count(category)|\n+----------+---------------+\n|    [Food]|         409379|\n|  [People]|         313646|\n|[Activity]|         108095|\n+----------+---------------+\nonly showing top 3 rows\n\n"
    }
   ],
   "source": [
    "# Find the top 3 category with emojis\n",
    "emoji_string_category.createOrReplaceTempView('emoji_string_category')\n",
    "spark.sql('''select category, count(category) from emoji_string_category group by category order by count(category) desc''').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3: For each user, create a variable to indicate their spending behavior profile. For\n",
    "example, if a user has made 10 transactions, where 5 of them are food and the other 5 are\n",
    "activity, then the user’s spending profile will be 50% food and 50% activity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-------+-------+-------------------+---------+\n|  user1|  user2|           datetime| category|\n+-------+-------+-------------------+---------+\n|1218774|1528945|2015-11-27 02:48:19|  [Trans]|\n|5109483|4782303|2015-06-17 04:37:04|   [Food]|\n|4322148|3392963|2015-06-19 00:05:31|       []|\n| 469894|1333620|2016-06-03 16:34:13|  [Event]|\n|2960727|3442373|2016-05-29 16:23:42|[Utility]|\n+-------+-------+-------------------+---------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "user_category=tokenized.select('user1','user2','datetime','category')\n",
    "user_category.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows with no category \n",
    "user_category=user_category.filter(F.size('category')>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3326219"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "user_category.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by the user id and category\n",
    "user_category.createOrReplaceTempView('user_category')\n",
    "user_category_order=spark.sql('''select * from user_category order by user1,category''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----+-------+-------------------+--------------------+\n|user1|  user2|           datetime|            category|\n+-----+-------+-------------------+--------------------+\n|    3|1204190|2016-10-08 18:56:24|              [Food]|\n|    3|     52|2016-09-22 08:30:09|            [People]|\n|    3|7854140|2016-10-08 20:36:13|           [Utility]|\n|    4| 968271|2014-02-03 22:51:33|[Activity, Activity]|\n|    4| 125527|2012-12-14 21:51:12|              [Food]|\n+-----+-------+-------------------+--------------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "user_category_order.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_category_order=user_category_order.select('user1', F.explode('category').alias(\"category\"))\\\n",
    "                                       .groupBy('user1','category')\\\n",
    "                                       .count()\\\n",
    "                                       .select('user1','category', 'count',F.sum('count').over(Window.partitionBy(\"user1\")).alias('total_count'))\\\n",
    "                                       .sort('user1', 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the proprotion of each category\n",
    "user1_category_order=user1_category_order.select('user1','category',(100*(round(((col(\"count\") /col(\"total_count\"))),2))).alias(\"proportion_%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----+--------+----+-----+-----+-------+------+-----------------+------------------+-------+\n|user1|Activity|Cash|Event| Food|Illegal|People|            Trans|            Travel|Utility|\n+-----+--------+----+-----+-----+-------+------+-----------------+------------------+-------+\n|    3|    null|null| null| 33.0|   null|  33.0|             null|              null|   33.0|\n|    4|    33.0|null| null| 33.0|   17.0|  null|             null|              17.0|   null|\n|   10|    10.0|null| null| 60.0|   null|  20.0|             10.0|              null|   null|\n|   11|    18.0|null| 27.0|  9.0|   null|  27.0|             null|               9.0|    9.0|\n|   12|    20.0|null| 20.0| 20.0|   null|  null|             null|              null|   40.0|\n|   13|    15.0|null| 11.0| 22.0|    4.0|  26.0|7.000000000000001|               4.0|   11.0|\n|   16|    null|null| null| 86.0|   null|  null|             null|14.000000000000002|   null|\n|   19|    33.0|null| 33.0| null|   null|  null|             null|              33.0|   null|\n|   34|    null|null| null| 67.0|   null|  null|             null|              33.0|   null|\n|   42|     8.0|null| 42.0| 17.0|    8.0|  25.0|             null|              null|   null|\n|   43|    25.0|null| null| 42.0|    8.0|  13.0|              8.0|               4.0|   null|\n|   47|    null|25.0| 25.0| 13.0|   13.0|  13.0|             null|              null|   13.0|\n|   52|    null|null| null|100.0|   null|  null|             null|              null|   null|\n|   56|   100.0|null| null| null|   null|  null|             null|              null|   null|\n|  126|   100.0|null| null| null|   null|  null|             null|              null|   null|\n|  129|   100.0|null| null| null|   null|  null|             null|              null|   null|\n|  149|    null|null| null| null|   null|  null|            100.0|              null|   null|\n|  164|    50.0|null| null| null|   null|  null|             null|              50.0|   null|\n|  173|    null|null| null|100.0|   null|  null|             null|              null|   null|\n|  192|    null|null| null|100.0|   null|  null|             null|              null|   null|\n+-----+--------+----+-----+-----+-------+------+-----------------+------------------+-------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "# Pivot the table\n",
    "user1_category_order=user1_category_order.groupBy('user1')\\\n",
    "                       .pivot(\"category\").sum(\"proportion_%\").sort(\"user1\")\n",
    "user1_category_order.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4: In the previous question, you got a static spending profile. However, life and social\n",
    "networks are evolving over time. Therefore, let’s explore how a user’s spending profile is\n",
    "evolving over her lifetime in Venmo. First of all, you need to analyze a user’s transactions in\n",
    "monthly intervals, starting from 0 (indicating their first transaction only ) up to 12.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for user profile every month\n",
    "\n",
    "# Break the datetime into months\n",
    "user_profile=user_category_order.selectExpr('user1',\"CAST( MONTHS_BETWEEN(datetime, FIRST_VALUE(datetime) OVER (PARTITION BY user1 ORDER BY datetime)) as INT) as month\",'category')\n",
    "# Filter months that are less than 12\n",
    "user_profile=user_profile.filter(F.col('month')<=12).sort('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the category\n",
    "user_profile=user_profile.select('user1','month', F.explode('category').alias(\"category\"))\\\n",
    "                         .groupBy('user1','month','category')\\\n",
    "                         .count()\\\n",
    "                         .select('user1','month','category','count', F.sum('count').over(Window.partitionBy(\"user1\",'month')).alias('total_count'))\\\n",
    "                                       .sort('user1', 'month','category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the proportion\n",
    "user_profile=user_profile.select(\"user1\",\"month\",'category','count','total_count',(100*(round(((col(\"count\") /col(\"total_count\"))),2))).alias(\"proportion_%\"))\n",
    "user_profile=user_profile.select(\"user1\",\"month\",'category',\"proportion_%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table\n",
    "user_profile_yearly = user_profile.groupBy('user1','month')\\\n",
    "                       .pivot(\"category\").sum(\"proportion_%\").sort(\"user1\",'month')\n",
    "user_profile_yearly.repartition(1).write.mode('overwrite').parquet(\"/Users/calvin/Desktop/Spring Quarter/Big data/Homework 2/user_profile_yearly.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation\n",
    "profile_count=tokenized.selectExpr('user1',\"CAST( MONTHS_BETWEEN(datetime, FIRST_VALUE(datetime) OVER (PARTITION BY user1 ORDER BY datetime)) as INT) as month\",'category').sort('user1','month')\n",
    "profile_count=profile_count.filter(F.col('month')<=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_count=profile_count.select('user1','month',F.explode('category').alias(\"category\"))\\\n",
    "                           .groupBy('user1','month','category')\\\n",
    "                           .count()\\\n",
    "                           .select('user1','month','category','count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_count.createOrReplaceTempView('profile_count')\n",
    "profile_mean=spark.sql('''select month, category, avg(count), stddev(count) from profile_count where month<=12 group by category, month order by category, month''')\n",
    "profile_mean_pd=profile_mean.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   month  category  avg(count)  stddev_samp(CAST(count AS DOUBLE))\n0      0  Activity    1.146139                            0.463561\n1      1  Activity    1.129598                            0.419170\n2      2  Activity    1.124987                            0.404048\n3      3  Activity    1.127956                            0.440148\n4      4  Activity    1.131385                            0.421853",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>month</th>\n      <th>category</th>\n      <th>avg(count)</th>\n      <th>stddev_samp(CAST(count AS DOUBLE))</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Activity</td>\n      <td>1.146139</td>\n      <td>0.463561</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Activity</td>\n      <td>1.129598</td>\n      <td>0.419170</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Activity</td>\n      <td>1.124987</td>\n      <td>0.404048</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Activity</td>\n      <td>1.127956</td>\n      <td>0.440148</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Activity</td>\n      <td>1.131385</td>\n      <td>0.421853</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "profile_mean_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}